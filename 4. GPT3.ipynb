{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSudfSolcEcm",
        "outputId": "deffa7e0-552b-4f00-ed26-fa22713e529f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.7/dist-packages (0.11.5)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.62.3)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.9)\n",
            "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /usr/local/lib/python3.7/dist-packages (from openai) (1.2.0.39)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2018.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pandas-stubs>=1.1.0.11->openai) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "#https://github.com/bhattbhavesh91/gpt-3-simple-tutorial/blob/master/gpt.py\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SaT0q2hOb30L"
      },
      "outputs": [],
      "source": [
        " \"\"\"Creates the Example and GPT classes for a user to interface with the OpenAI API.\"\"\"\n",
        "import openai\n",
        "\n",
        "def set_openai_key(key):\n",
        "    \"\"\"Sets OpenAI key.\"\"\"\n",
        "    openai.api_key = key\n",
        "\n",
        "class Example():\n",
        "    \"\"\"Stores an input, output pair and formats it to prime the model.\"\"\"\n",
        "\n",
        "    def __init__(self, inp, out):\n",
        "        self.input = inp\n",
        "        self.output = out\n",
        "\n",
        "    def get_input(self):\n",
        "        \"\"\"Returns the input of the example.\"\"\"\n",
        "        return self.input\n",
        "\n",
        "    def get_output(self):\n",
        "        \"\"\"Returns the intended output of the example.\"\"\"\n",
        "        return self.output\n",
        "\n",
        "    def format(self):\n",
        "        \"\"\"Formats the input, output pair.\"\"\"\n",
        "        return f\"input: {self.input}\\noutput: {self.output}\\n\"\n",
        "\n",
        "\n",
        "class GPT:\n",
        "    \"\"\"The main class for a user to interface with the OpenAI API.\n",
        "    A user can add examples and set parameters of the API request.\"\"\"\n",
        "\n",
        "    def __init__(self, engine='davinci',\n",
        "                 temperature=0.5,\n",
        "                 max_tokens=512):\n",
        "        self.examples = []\n",
        "        self.engine = engine\n",
        "        self.temperature = temperature\n",
        "        self.max_tokens = max_tokens\n",
        "\n",
        "    def add_example(self, ex):\n",
        "        \"\"\"Adds an example to the object. Example must be an instance\n",
        "        of the Example class.\"\"\"\n",
        "        assert isinstance(ex, Example), \"Please create an Example object.\"\n",
        "        self.examples.append(ex.format())\n",
        "\n",
        "    def get_prime_text(self):\n",
        "        \"\"\"Formats all examples to prime the model.\"\"\"\n",
        "        return '\\n'.join(self.examples) + '\\n'\n",
        "\n",
        "    def get_engine(self):\n",
        "        \"\"\"Returns the engine specified for the API.\"\"\"\n",
        "        return self.engine\n",
        "\n",
        "    def get_temperature(self):\n",
        "        \"\"\"Returns the temperature specified for the API.\"\"\"\n",
        "        return self.temperature\n",
        "\n",
        "    def get_max_tokens(self):\n",
        "        \"\"\"Returns the max tokens specified for the API.\"\"\"\n",
        "        return self.max_tokens\n",
        "\n",
        "    def craft_query(self, prompt):\n",
        "        \"\"\"Creates the query for the API request.\"\"\"\n",
        "        return self.get_prime_text() + \"input: \" + prompt + \"\\n\"\n",
        "\n",
        "    def submit_request(self, prompt):\n",
        "        \"\"\"Calls the OpenAI API with the specified parameters.\"\"\"\n",
        "        response = openai.Completion.create(engine=self.get_engine(),\n",
        "                                            prompt=self.craft_query(prompt),\n",
        "                                            max_tokens=self.get_max_tokens(),\n",
        "                                            temperature=self.get_temperature(),\n",
        "                                            top_p=1,\n",
        "                                            n=1,\n",
        "                                            stream=False,\n",
        "                                            stop=\"\\ninput:\")\n",
        "        return response\n",
        "\n",
        "    def get_top_reply(self, prompt):\n",
        "        \"\"\"Obtains the best result as returned by the API.\"\"\"\n",
        "        response = self.submit_request(prompt)\n",
        "        return response['choices'][0]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DxD_k2Dkd9zL"
      },
      "outputs": [],
      "source": [
        "#https://beta.openai.com/docs/api-reference/completions/create\n",
        "\n",
        "gpt = GPT(engine=\"davinci\",\n",
        "          temperature=0.4,\n",
        "          max_tokens=512)\n",
        "\n",
        "set_openai_key('API key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "smJTMiHGgxg5"
      },
      "outputs": [],
      "source": [
        "#Few shot learning\n",
        "\n",
        "gpt.add_example(Example('KEYWORD : Cancer pathology report ;  Natural language processing ;  Named entity recognition ;  Convolutional neural network ;  Data modeling ;  Distributed research network ;  Common data model',\n",
        "''' ABSTRACT: As per the cancer statistics, the total number of cancer patients in Korea as of 2017 is 232,255, which is 1,019 more compared to 2016. Various tests have been conducted to diagnose and treat cancer; consequently, a large amount of unstructured clinical data, including texts, images, and videos, are produced. The cancer pathology report is an extremely important information source to provide guidance on cancer diagnosis and treatment because it contains information on cancer type, characteristics, and cancer stages. However, this report is usually in the form of free-descriptive texts and such texts should be converted into structured ones such that machines can understand. Therefore, this study aims at developing a cancer pathology data model to create a structured data, and, based on such a data model, develop a cancer pathology data conversion methodology that uses a model based on natural language processing (NLP) for information extraction. For this purpose, we have collected overseas and domestic pathology reports and documents related to breast, thyroid, colorectal, and gastric cancers, whose occurrence is high in Korea. We then analyzed the data system, as well as established a dictionary of vocabulary used in these studies. Accordingly, we developed a cancer pathology model comprising four tables of specimen basic information, specimen common observation information, specimen-specific observation information, and immunohistochemical test information.\n",
        "'''))\n",
        "\n",
        "gpt.add_example(Example('KEYWORK :  app prediction ;  natural language processing ;  neural network',\n",
        "'''ABSTRACT: The application’s resources management is an important task in smartphones. Optimizing the applications launch process results in a faster and efficient system, impacting directly the user’s experience. Predicting the next application that will be used can orient the smartphone to address the system resources to the correct application, making the system more intelligent and efficient. Neural Networks have been presenting outstanding results in the state-of-the-art for mapping large sequences of data, outperforming all previous classification and prediction models. Recurrent neural networks (RNN) is an artificial neural network associated with sequence models and it can recognize patterns in sequences. One of the areas that uses RNN is the natural language processing (NLP). Given a sequence of words, the NLP can learn how the words are organized in sentences, making it possible to predict the next word given a group of previous words. We propose building a predictive model inspired by the NLP. However, instead of using words, we will use previous applications to predict the next application. Moreover, some context features, such as timestamp and energy record, will be included in the prediction model in order to evaluate the impact of the features on the performance. We will provide the next application prediction result and also we will extend to the top-k possible candidates for the next application.\n",
        "'''))\n",
        "\n",
        "\n",
        "gpt.add_example(Example('KEYWORK : Usability ;  Qualitative data ;  Text-processing algorithm ;  Word2Vec ;  Natural Language Processing',\n",
        "'''ABSTRACT: The quality of a product to be usable has become the basic requirement in consumer’s perspective while failing the requirement ends up the customer from not using the product. Identifying usability issues from analyzing quantitative and qualitative data collected from usability testing and evaluation activities aids in the process of product design, yet the lack of studies and researches regarding analysis methodologies in qualitative text data of usability field inhibits the potential of these data for more useful applications. While the possibility of analyzing qualitative text data found with the rapid development of data analysis studies such as natural language processing field in understanding human language in computer, and machine learning field in providing predictive model and clustering tool.\n",
        "'''))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "THRVIwu1isOp",
        "outputId": "2cc3b53d-9e54-4be0-a7fc-aa5b8d8d249a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'output: ABSTRACT: This paper presents a set of techniques for extracting sequences of functions from Android applications. The techniques are based on the use of a set of heuristics that identify functions in Android applications and a set of machine learning classifiers that extract sequences of functions. The classifiers are trained with a set of labeled sequences of functions extracted from a set of Android applications. The classifiers are evaluated with a set of Android applications and the results show that they are able to extract sequences of functions with high precision and recall.\\n\\n'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"KEYWORD :applications; input; functions; set; sequence\" \n",
        "output = gpt.submit_request(prompt)\n",
        "output.choices[0].text"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "GPT3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
