{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DTM"
      ],
      "metadata": {
        "id": "JqvfIVG4Ifox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting"
      ],
      "metadata": {
        "id": "YB4nu-l2ImUG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpfWInX0IGzG"
      },
      "outputs": [],
      "source": [
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import ldaseqmodel\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import pandas as pd\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "keyword_num = 6  # 키워드 개수 (수정할 수 있는 부분)\n",
        "data_size = 1200  # 데이터 크기, 각 키워드 별로 200개씩 키워드 6개이므로 년도별 1200개(수정할 수 있는 부분)\n",
        "topic_num = 50  # Topic의 개수 (수정할 수 있는 부분)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence tokenize"
      ],
      "metadata": {
        "id": "nKIAqLXfIvO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_tokenized_list = []  # 각 년도별로 tokenized 결과 저장 (년도별로 총 n개씩 저장됨)\n",
        "for year in range(2017, 2022):\n",
        "  for i in range(0, keyword_num * 2, 2):\n",
        "    data = pd.read_excel(str(year) + \"_result.xlsx\")\n",
        "    data.drop(['Unnamed: 0'], axis=1, inplace=True)  # Index 표시 제거\n",
        "\n",
        "    keyword = data.columns[i]\n",
        "    keyword_data = data[keyword].tolist()\n",
        "\n",
        "    for j in range(len(keyword_data)):\n",
        "      temp = []\n",
        "      tokenized_sentence = word_tokenize(keyword_data[j])\n",
        "      for word in pos_tag(tokenized_sentence):\n",
        "        if ('NN' in word[1]) and (word[0] not in stopwords.words('english')):\n",
        "            # 단어 앞 뒤에 필요 없는 기호 제거\n",
        "            text = word[0].strip('\\\\')\n",
        "            text = text.strip('$')\n",
        "            text = text.strip('-')\n",
        "            text = text.strip('#')\n",
        "            text = text.strip('^')\n",
        "            text = text.strip('/')\n",
        "            text = text.strip('%')\n",
        "            text = text.strip('.')\n",
        "            text = text.strip('_')\n",
        "            text = text.strip('~')\n",
        "            text = text.strip('=')\n",
        "            text = text.strip('+')\n",
        "            text = text.strip('*')\n",
        "            text = text.strip(',')\n",
        "            if(text == \"\"):\n",
        "              continue\n",
        "            temp.append(text)\n",
        "\n",
        "      keyword_tokenized_list.append(temp)"
      ],
      "metadata": {
        "id": "IVb-RVgQIMs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DTM"
      ],
      "metadata": {
        "id": "x5_1nxp5JrUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict = Dictionary(keyword_tokenized_list)\n",
        "corpus = [my_dict.doc2bow(text) for text in keyword_tokenized_list]\n",
        "\n",
        "# 2017 ~ 2021이므로 총 5개 (1200개씩)\n",
        "time_slice = [data_size, data_size, data_size, data_size, data_size]\n",
        "# num_topics : tuning해야하는 hyperparameter (토픽 수를 얼마나 설정할 것인지)\n",
        "ldaseq = ldaseqmodel.LdaSeqModel(\n",
        "    corpus=corpus, id2word=my_dict, time_slice=time_slice, num_topics=topic_num)\n",
        "\n",
        "for i in range(topic_num):\n",
        "  df = pd.DataFrame()\n",
        "  for j in range(5):\n",
        "    li = ldaseq.print_topic_times(i, top_terms=len(my_dict))[j]\n",
        "    li.sort()  # Sorting data\n",
        "    df[j + 2017] = [val[1] for val in li]\n",
        "\n",
        "    if(j == 0):\n",
        "      df.index = [val[0] for val in li]\n",
        "\n",
        "  df.to_excel(\"topic\" + str(i + 1) + \"_dtm.xlsx\")"
      ],
      "metadata": {
        "id": "ngGtFQbgIO8M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}