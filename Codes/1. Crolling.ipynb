{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Crolling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Crolling"
      ],
      "metadata": {
        "id": "kIZIwTqsWdxY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh2XMHPyWVBQ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "keyword = ['Transformer', 'segmentation','GAN', \"object detection\", \"encoder\", \"decoder\"] # 추출할 키워드\n",
        "data_size = 200 # 추출할 논문 수\n",
        "url_front = 'https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term='\n",
        "url_mid = '&terms-0-field=all&classification-computer_science=y&classification-physics_archives=all&classification-include_cross_list=include&date-filter_by=specific_year&date-year='\n",
        "url_back = '&date-from_date=&date-to_date=&date-date_type=submitted_date&abstracts=show&size=200&order=-announced_date_first&start='\n",
        "\n",
        "for year in range(2017, 2022):\n",
        "    df = pd.DataFrame() # 년도 별로 검색된 결과를 저장하는 dataframe\n",
        "    for key in keyword:\n",
        "        text_store = [] # key에 해당하는 키워드를 year에 해당하는 년도 기준으로 검색된 결과를 저장하는 리스트\n",
        "        title_store = []\n",
        "\n",
        "        for size in range(0, data_size, 200):\n",
        "            url = url_front + key + url_mid + str(year) + url_back + str(size)\n",
        "            res = requests.get(url)\n",
        "            soup = BeautifulSoup(res.content, 'html.parser')        \n",
        "        \n",
        "            parser = soup.find_all(attrs={'class':'abstract mathjax'})\n",
        "            title_parser = soup.find_all(attrs={'p', 'title is-5 mathjax'})\n",
        "\n",
        "            for text in parser:\n",
        "                text_value = text.contents[5].get_text()          \n",
        "                text_store.append(text_value[:-7].strip())\n",
        "\n",
        "            for title in title_parser:\n",
        "                title_value = \"\"\n",
        "                for t in title.contents:\n",
        "                    title_value += t.get_text()\n",
        "                title_store.append(title_value.strip())\n",
        "\n",
        "        df[key] = text_store\n",
        "        df[key + \"_source\"] = title_store\n",
        "    \n",
        "    df.to_excel(str(year) + \"_result.xlsx\")\n",
        "    print(year, \"result is completed\")"
      ]
    }
  ]
}